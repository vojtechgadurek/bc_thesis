\chapter{Dotnet and C\# Preliminarie}

Vice omacky

\section{Memory}
\subsection{Heap and Stack}
There are two main types of memory: heap and stack. One should take care not to be confused by the name heap, as it has very little to do with the data structure used for finding the minimum in logarithmic time.

\subsubsection{Stack}
The stack and heap work quite differently. The stack functions as we would expect a stack to function: data is pushed from the top and also taken from the top. This is useful for recursive parts of our program and is mainly used by methods. One should easily see, that methods are in their nature recursive. As methods have only to options: call same other method or they can return. This leads to a tree structure. When we call a method, we first save the values held by accumulators (registers used by the processor) so they are free to be used by the called method. These values are saved to the on the top of stack. Then, after the called method finishes, the saved data is loaded back. Methods may also put their own data on the stack, but it is important to remember that every piece of data on the stack is not safe to use after the method that placed it there has returned. As the stack pointer is now under these data, so any method called later can and probably will overwrite them.

\subsubsection{Heap}
Sometimes we want to save data between method calls. The heap is used for this purpose. We request some memory of a certain size from the heap and then we are given such memory, that is guaranteed not be used. When we no longer need this memory, we return it back to the heap. This process is called allocating and deallocating memory.

This sounds simple, but there are two problems. The first problem is that if we do not deallocate, we may run out of memory. The second problem is that when we free some memory, some part of the program may still treat that part memory as if it still holded original data, but that may or may not be true. These are real problems and may cause dangerous bugs and security issues, especially the latter.

\subsection{Value and Reference Types}

We now need to discuss C\# types. There are two kinds of C\# types: Value and Reference.

\subsubsection{Value Types}

Value types live on the stack. Value types are for example integers of any length or floats. When we speak about an instance with a value type, we use the term value. We may also define our own value types, such as a complex number:

\begin{lstlisting}
struct ComplexNumber{
    public double Real;
    public double Imaginary;
}
\end{lstlisting}
We should look on struct more as a syntax sugar for grouping some fields together. therefore when we call a method that has a value type as an argument, the value is passed by coping every single field. This behaviour is called pass by copy and it leads to some interesting behaviour. For example:

\begin{lstlisting}
var x  =  new ComplexNumber(){Real = 1, Imaginary = 1};
var y  = new ComplexNumber(){Real = 1, Imaginary = 1};
var z = Add(x, y);

ComplexNumber Add(ComplexNumber a, ComplexNumber b){
    a.Real += b.Real;
    a.Imaginary += b.Imaginary;
    return a;
}
\end{lstlisting}

In this example, z.Real is 2, but x.Real is still 1. This is because the field, were copied, thus when we add b.Real to a.Real, x.Real was not changed.
This is something, we have to take remeber, when working with values, also this behaviour means the more field a value type has, the more expensive is to pass it to some method or to copy it as all the field need to be copied.

\subsubsection{Reference Types}
Reference types live on the heap. Instances of reference types are called objects. Every object has its data located on the heap, where it stays until deallocated. When we call a method that has a reference type as an argument, we just need to pass information about where the object lies on the heap. This information is called a reference, and thus this process is called argument passing by reference.

We may define our own reference types using the keyword class:

\begin{lstlisting}
class ComplexNumber{
    public double Real;
    public double Imaginary;
}
\end{lstlisting}

We are going to use the same example as we used for value types.

\begin{lstlisting}
var x  =  new ComplexNumber(){Real = 1, Imaginary = 1};
var y  = new ComplexNumber(){Real = 1, Imaginary = 1};
var z = Add(x, y);

ComplexNumber Add(ComplexNumber a, ComplexNumber b){
    a.Real += b.Real;
    a.Imaginary += b.Imaginary;
    return a;
}
\end{lstlisting}

Although the code is the same, the result is not. z.Real is still 2, but x.Real is now 2. The reason is that x and z are just references pointing to the same object. Thus, when we pass an object to a method, the only cost is a copy of the reference. One may ask why we should use value types when they are more expensive to pass to methods. The answer is that allocations to the heap are problematic and come with their own costs.

\subsection{Garbage Collector}
In the first section, we learned about the problems with the heap. Luckily for us, C\# is a memory-safe language. This means it solves both problems for us by using a garbage collector (GC). The garbage collector keeps track of all objects allocated by our program.

\begin{rem}
    This is technically not true, as C\# allows opting out of the safe context. However, this is something that is used very rarely and only when performance or the need for interop with other languages is required. One seeking such behavior should check unsafe context and Memory<T>.
\end{rem}

When the program needs more memory, it enters the garbage collecting phase, during which some objects to which no reference points are found and the memory used by them is freed. The word some is important, as the process is not deterministic, and we cannot be sure whether or when some unused objects will be collected.

This process is also expensive. This is normally not a problem, but when we allocate a lot in a hot path, it will probably hurt us in terms of performance. (Allocating a new object is also not costless). Also, some garbage collectors need to stop all computations. This may not be feasible in some applications where even short delays are not acceptable, for example, in high-frequency trading.

This problem has only one solution: allocate less. It is possible to achieve this in many ways. Some methods are used quite normally. Some are very obscure and used very sporadically. Using values instead of objects is very common; one just needs to take care of the fact that pass by copy might get expensive for values having many fields. The next trick in the book is to recycle objects after they are no longer going to be used. This is usually done via pools and for some object, that are generaly expensive to allocate we are given a implemation in th base library. One iterested should check ArrayPool<T> or ThreadPool<T>.

\section{Abstraction, Virtual Methods, Delegates, Interfaces}

\subsection{Inheritance and Virtual Methods}
Imagine implementing a probabilistic algorithm. This algorithm has a very low chance of cycling and never ending. Our goal is to use some heuristics to determine whether the current state is recoverable. A very simple heuristic is to set a maximum number of steps. We can implement the algorithm like this:

\begin{lstlisting}
class ProbAlg {
    //Some fields ...
    int _nRounds = 0;
    int _maxNRounds = 100;

    bool StopCondition(){
        return _nRounds < _maxNRounds;
    }

    void Run(){
        while (StopCondition()){
            //Some computation 
            _nRounds += 1;
        }
    }
}
\end{lstlisting}

Later we might want to implement a different stop condition and compare how the algorithms perform. One option would be to use virtual methods and inheritance.

\begin{lstlisting}
class ProbAlg {
    //Some fields ...
    int _nRounds = 0;
    int _maxNRounds = 100;

    virtual internal bool StopCondition(){
        return _nRounds < _maxNRounds;
    }

    void Run(){
        while (StopCondition()){
            //Some computation 
            _nRounds += 1;
        }
    }
}

class ProbAlgBetterStopCondition : ProbAlg {
    override bool StopCondition(){
        return SuperGoodHeuristic();
    }
}
\end{lstlisting}

The virtual keyword marks the method as virtual, and the internal keyword marks the method as internal, so they may be used by classes inheriting from ProbAlg but not by any other class. Virtual methods' implementations may be overridden by their children. This is important as, during compile time, the compiler does not know which implementation is going to be used beforehand. This may cause some performance issues as the compiler cannot perform some of its optimizations.

\begin{lstlisting}

ProgAlg x = Create(); 
//Is x ProgAlg or ProbAlgBetterStopCondition? 
//We do not know during compile time. 
//x could possibly be either.

ProgAlg Create(){
    return //Creates some object of type AlgProg
}
\end{lstlisting}

\subsection{Inheritance on Value Types}
Value types cannot be inherited. This makes sense as values are passed using copies, but children may declare new fields, thus needing more memory than their parents. This is not a problem for reference types as references always have the same size.

\subsection{Interfaces}

Let's say we need to work with groups but don't want to implement a special function for each group type. In this case, interfaces are the way to go.

\begin{lstlisting}
interface IGroupElement {
    IGroupElement Add(IGroupElement a);
    IGroupElement Inverse();
}

struct Z5 : IGroupElement {
    public readonly int Value;
    // Constructor
    public Z5(int value) {
        Value = value;
    }

    IGroupElement Add(IGroupElement a) {
        return new Z5((Value + ((Z5)a).Value) % 5);
    }

    IGroupElement Inverse() {
        return new Z5((5 - Value) % 5);
    }
}

IGroupElement AddAll(List<IGroupElement> elementsToAdd) {
    // Aggregate is C#'s version of fold
    return elementsToAdd.Aggregate((a, b) => a.Add(b));
}
\end{lstlisting}

`AddAll` is going to work for any implementation of `IGroupElement`. However, there are some issues. The first is that `List<IGroupElement>` may hold any value or object implementing `IGroupElement`. This can result in runtime errors since we haven't defined behavior for adding elements from two different groups.

There's also a performance issue regarding using interfaces over value types. `List<IGroupElement>` holds references. This is problematic because value types live on the stack and not on the heap, meaning they have to be moved to the heap, creating a new object. This process, called boxing, goes against the reason for using value types: to minimize heap allocations.

\subsection{Generics}
The aforementioned problem has a solution called generics. Generics in C\# are similar to templates in C++. Let's look at how to solve this problem using generics.

\begin{lstlisting}
interface IGroupElement<T> {
    T Add(T a);
    T Inverse();
}

struct Z5 : IGroupElement<Z5> {
    public readonly int Value;
    // Constructor
    public Z5(int value) {
        Value = value;
    }

    Z5 Add(Z5 a) {
        return new Z5((Value + a.Value) % 5);
    }

    Z5 Inverse() {
        return new Z5((5 - Value) % 5);
    }
}

T AddAll<T>(List<T> elementsToAdd) where T : IGroupElement<T> {
    // Aggregate is C#'s version of fold
    return elementsToAdd.Aggregate((a, b) => a.Add(b));
}
\end{lstlisting}

We have now defined a generic version of `AddAll`. `T` can be substituted by any type that fulfills all constraints. Currently, we have defined only one constraint: that `T` implements `IGroupElement<T>`. Now, `List<T>` can hold only objects or values of one type or their children. This solves the issue of different types in `List<IGroupElement>` causing runtime errors.

Let's look at how generics behave for value and reference types. For every reference type, there is just one shared CIL code. For value types, every value type has its own CIL code. The code is compiled for the specific type when it is first needed during runtime. This is important because it means the value type does not need to be boxed. \cite{Generics1}

\section{Dotnet and Just-In-Time Compilation}

Every programming language needs to be translated into machine code. There are two main approaches: compiling and interpreting. Both approaches have their benefits and drawbacks in terms of performance, security, and portability. By portability, we mean the ability to run our software easily on many different machines and architectures.

Compiled languages are translated to assembly before the program starts. This has two advantages. First, security: we can send our clients just the machine code for their specific machine, keeping the source code private. Second, performance: the processor gets the code already translated and doesn't need to do any additional work. The compiler can also optimize the code to run faster. The main problem is that not all processors have the same instruction sets, so we have to compile our software for each of them.

Interpreted languages use an interpreter to read their instructions and translate them to machine code during runtime. This costs time. However, any machine equipped with such an interpreter can run the native code.

There is also a third option: JIT (Just-In-Time) compilation, which lies somewhere in the middle. It involves both compiling and interpreting. It first takes our code written in the language and translates it to IL (Intermediate Language). IL contains most instructions used by modern processors. IL code is then translated to machine code during runtime when first needed by our program.

C\# is a JIT language. Native code is first translated to CIL (Common Intermediate Language), and then when the program runs, the CLR (Common Language Runtime) does the heavy work of compiling from CIL to machine code during runtime.

\section{Compiler Optimizations}

As C\# has a compiler, there are some optimizations and potential performance bottlenecks one should be aware of.

\subsubsection{Cost of Method Call}
Calling methods is not free. We need to do some preparations, mainly saving values from accumulators to the stack and then loading them back. This cost is very small, but it can add up if the method body is very small. For example:

\begin{lstlisting}
int AddTwo(int x) {
    return AddOne(AddOne(x));
}

int AddOne(int x) {
    return x + 1;
}
\end{lstlisting}

\subsubsection{Inlining}
The compiler can solve this problem by inlining. It may replace the method call with its body, saving the cost of the method call. So we get something like this:

\begin{lstlisting}
int AddTwo(int x) {
    return x + 2;
}

int AddOne(int x) {
    return x + 1;
}
\end{lstlisting}

Inlining is very powerful as it allows us to write very small methods without losing performance. However, not all methods can be inlined. A method can only be inlined when the compiler knows which method is going to be called.

\subsubsection{Simple Example}
\begin{lstlisting}
List<int> FilterOdd(List<int> input) {
    var answer = new List<int>();
    foreach(var number in input) {
        if (IsOdd(number)) answer.Add(number);
    }
    return answer;
}
\end{lstlisting}

This code works, but what if we now need to implement a filter that filters prime numbers? We might modify the preceding code:

\begin{lstlisting}
List<int> FilterPrime(List<int> input) {
    var answer = new List<int>();
    foreach(var number in input) {
        if (IsPrime(number)) answer.Add(number);
    }
    return answer;
}
\end{lstlisting}

If we look closely, we see that the code of `FilterPrime` and `FilterOdd` are very similar. Therefore, it would be nice to abstract the behavior of the filter. We can do something like this:

\subsubsection{Solution Using Delegates}
\begin{lstlisting}
List<int> Filter(
    List<int> input, 
    Func<int, bool> filterCondition
) {
    var answer = new List<int>();
    foreach(var number in input) {
        if (!filterCondition(number)) continue;
        answer.Add(number);
    }
    return answer;
}
\end{lstlisting}

Now, `filterCondition` may still be a very short method, but the compiler does not know it at the time of compilation, so it cannot be inlined. Similarly, this would happen if we were using an interface.

\subsubsection{Solution Using Interface}
\begin{lstlisting}
interface IFilter {
    bool Invoke(int number);
}

List<int> Filter(
    List<int> input, 
    IFilter filterCondition
) {
    var answer = new List<int>();
    foreach(var number in input) {
        if (!filterCondition.Invoke(number)) continue;
        answer.Add(number);
    }
    return answer;
}
\end{lstlisting}

There is a solution to this problem. We'll first show the code and then explain why it works.

\subsubsection{Solution Using Generic Over Struct Interface Method}
\begin{lstlisting}
interface IFilter {
    bool Invoke(int number);
}

List<int> Filter<Filter>(
    List<int> input, 
    Filter filterCondition
) where Filter : struct, IFilter {
    var answer = new List<int>();
    foreach(var number in input) {
        if (!filterCondition.Invoke(number)) continue;
        answer.Add(number);
    }
    return answer;
}
\end{lstlisting}

We used a struct constraint to enforce that `Filter` is a value type. This means we get value behavior on generics, thus generating unique CIL code for every type of filter. Also, since `filter` is a struct, it cannot have children, so there is no way to override the `Invoke` method. This means the compiler knows there is only one possible implementation of such a method, thus it can inline it.

\subsection{When the Compiler Inlines}
The .NET compiler uses heuristics to determine whether to inline and where to inline, as inlining may not always be beneficial. There is no way to enforce inlining in C\#, but we can give hints to the compiler. This is done using attributes. One can use `[MethodImpl(MethodImplOptions.AggressiveInlining)]` to increase the chance of a method being inlined and `[MethodImpl(MethodImplOptions.NoInlining)]` to forbid inlining for that method.

\section{Constant Optimization}
When we use constants, the compiler may optimize their use. For example:

\begin{lstlisting}
int AddTwo(int a) {
return a + 1 + 1;
}
\end{lstlisting}

Is optimized to:

\begin{lstlisting}
int AddTwo(int a) {
return a + 2;
}
\end{lstlisting}

This saves us some unnecessary calculations that would otherwise need to be repeated. Modern compilers are quite advanced and can replace some expensive arithmetic operations, such as division and modulo, with less expensive ones, like multiplication. This can result in a significant performance boost, as demonstrated by the following experiment:

Sometimes we do not know the value to divide with beforehand, but we would still like to benefit from compiler optimizations, as we expect to do many division with same divisor. There are three methods, how to achieve that in C\# Expression Trees, Struct Delegates with Runtime types or code generation. We shortly dicuss all three methods. All of them are quite advanced and should be used only, when it is really necessary.

\subsection{Expression Trees}
If we look on code, we may see it having a tree structure (generally its DAG), where nodes are some functions and leafs are constanst or paramenters. For example: 
\begin{lstlisting}
int IfOddAddOne(int input) {
    if (input % 2 == 1){
        return input + 1
    }
    return input;
}
\end{lstlisting}

Might get translated to this: TODO graph

\iffalse
\digraph{expressionTree1}{
  const_1 -> b0;
  input -> "+"
  const_1 -> "+"
  input -> "\%"
  "\%" -> "=="
  const_1 -> "=="
  "==" -> if [label = "check"]
  input -> if [label = "check is false"]
  "+" -> if [label = "check is true"]
}
\fi

C\# allows us to build such expressions during runtime and then to compile them and use as any other delegate.
If we wanted a expression tree for the previous code, we could do that with something like this:

\begin{lstlisting}
//This code was partially generated by ChatGpt
using System.Ling.Expressions
//Parameters
var input = Expression.Parameter(typeof(int), "input");
//Constants
var constOne = Expression.Constant(1);
var constTwo = Expression.Constant(2);
// mod = input % 2 
var mod = Expression.Modulo(input, constTwo);
// if-else statement
var condition = Expression.Equal(mod, constOne);
var addOne = Expression.Add(input, constOne);
var ifTrue = addOne;
var ifFalse = input;
//Condition
var ifElse = Expression.Condition(condition, ifTrue, ifFalse);
Expression<Func<int, int>> lambda 
= Expression.Lambda<Func<int, int>>(ifElse, input);
Func<int, int> compiled = lambda.Compile();
\end{lstlisting}

One can see, that no output is assigned. This is because in Expression Trees the returned value is always the value of last expression. There are few disatvantages of Expression Trees. The first and most significant is, that the code is not statically checked. For example this code is going to compile, but fails during runtime.

\begin{lstlisting}
//This code was partially generated by ChatGpt
using System.Ling.Expressions
//Parameters
var input = Expression.Parameter(typeof(int), "input");
//Constants
var constOne = Expression.Constant(1);
var constA = Expression.Constant('A');
var add = Expression.Add(constOne, constA);

Expression<Func<int, int>> lambda 
= Expression.Lambda<Func<int>>(add);

lambda.Compile() //Fails there 

// but x = 1 + 'A' does not compile
\end{lstlisting}
This is accutally double edged sword as it allows us to have ducktyping, but at no or little cost to performance. 




\begin{lstlisting}


\end{lstlisting}